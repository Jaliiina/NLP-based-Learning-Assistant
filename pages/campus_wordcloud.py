import streamlit as st
from io import BytesIO

from aid_integrated.campus import wordcloud_utils


def _fig_to_png_bytes(fig) -> bytes:
    buf = BytesIO()
    fig.savefig(buf, format="png", dpi=180, bbox_inches="tight")
    return buf.getvalue()


def render() -> None:
    st.header("â˜ï¸ æ™ºèƒ½è¯äº‘ç”Ÿæˆ")

    st.markdown(
        """
        <div style="background-color:#f8fafc;padding:20px;border-radius:16px;border:1px solid #e2e8f0;
        box-shadow:0 4px 16px rgba(0,0,0,0.06);margin:16px 0 24px 0;">
        <div style="font-size:16px;color:#1e293b;line-height:1.8;">
            <b style="font-size:18px;color:#1e40af;">è¿™ä¸ªåŠŸèƒ½èƒ½å¸®ä½ åšä»€ä¹ˆï¼Ÿ</b><br/>
            <span style="color:#2563eb;font-weight:700;">ğŸ“Š æŒ‰ç« èŠ‚ç”Ÿæˆè¯äº‘</span>ï¼šä¸ºæ¯ä¸ªä¸Šä¼ çš„ç« èŠ‚æ–‡ä»¶ç”Ÿæˆç‹¬ç«‹è¯äº‘ï¼Œç›´è§‚å±•ç¤ºå„ç« èŠ‚æ ¸å¿ƒè¯æ±‡<br/>
            <span style="color:#2563eb;font-weight:700;">âš–ï¸ æƒé‡é©±åŠ¨çš„è¯äº‘</span>ï¼šåŸºäºç®—æ³•è®¡ç®—è¯æ±‡é‡è¦æ€§ï¼Œæ ¸å¿ƒè¯æ±‡æ˜¾ç¤ºæ›´å¤§æ›´çªå‡º<br/>
            <span style="color:#2563eb;font-weight:700;">ğŸ¨ è‡ªå®šä¹‰è¯äº‘æ ·å¼</span>ï¼šå¯è°ƒæ•´èƒŒæ™¯è‰²ã€æœ€å¤§è¯æ•°<br/>
            <span style="color:#2563eb;font-weight:700;">ğŸŒ å…¨å±€è¯äº‘ç”Ÿæˆ</span>ï¼šåˆå¹¶æ‰€æœ‰ç« èŠ‚ï¼Œç”Ÿæˆæ•´ä»½è®²ä¹‰çš„æ ¸å¿ƒè¯æ±‡è¯äº‘
        </div>
        <div style="margin-top:16px;background:#eff6ff;padding:12px;border-radius:10px;color:#1e40af;">
            ğŸ’¡ <b>TF-IDF æ¨¡å‹ï¼š</b>ä¾§é‡ã€ŒåŒºåˆ†åº¦ã€â†’ æ‰¾å‡ºæœ¬ç« èŠ‚ç‹¬æœ‰çš„æ ¸å¿ƒè¯<br/>
            ğŸ’¡ <b>TextRank æ¨¡å‹ï¼š</b>ä¾§é‡ã€Œé‡è¦æ€§ã€â†’ æ‰¾å‡ºæœ¬ç« èŠ‚å†…æœ€æ ¸å¿ƒçš„é€šç”¨è¯<br/>
            âœ¨ é€‰æ‹©å»ºè®®ï¼šæƒ³åŒºåˆ†å„ç« èŠ‚ç‰¹è‰²ç”¨TF-IDFï¼Œæƒ³æ‰¾å…¨å±€æ ¸å¿ƒç”¨TextRank
        </div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    st.session_state.setdefault("campus_wordcloud_results", {})

    has_chapter_data = bool(st.session_state.get("chapter_clean_texts"))
    has_global_data = bool(isinstance(st.session_state.get("clean_text"), str) and st.session_state["clean_text"].strip())

    if not has_chapter_data and not has_global_data:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ã€ŒğŸ“š æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ã€ä¸Šä¼ å¹¶æ¸…æ´—æ–‡æœ¬ï¼")
        return

    generate_mode = st.radio(
        "ç”Ÿæˆæ¨¡å¼",
        ["æŒ‰ç« èŠ‚ç”Ÿæˆï¼ˆæ¯ä¸ªæ–‡ä»¶ä¸€å¼ è¯äº‘ï¼‰", "å…¨å±€ç”Ÿæˆï¼ˆæ‰€æœ‰æ–‡ä»¶åˆå¹¶ï¼‰"],
        index=0 if has_chapter_data else 1,
    )

    st.subheader("âš™ï¸ è¯äº‘å‚æ•°")
    col1, col2, col3 = st.columns(3)
    with col1:
        weight_method = st.radio("æƒé‡æ¨¡å‹", ["TF-IDF", "TextRank"], index=0)
    with col2:
        bg_color = st.color_picker("èƒŒæ™¯é¢œè‰²", value="#ffffff")
    with col3:
        max_words = st.slider("æœ€å¤§è¯æ•°", 50, 500, 200, 50)

    if st.button("ç”Ÿæˆæ™ºèƒ½è¯äº‘", type="primary", width="stretch"):
        results: dict = {
            "generate_mode": generate_mode,
            "weight_method": weight_method,
            "bg_color": bg_color,
            "max_words": int(max_words),
            "chapter": {},
            "global": None,
        }
        if generate_mode == "æŒ‰ç« èŠ‚ç”Ÿæˆï¼ˆæ¯ä¸ªæ–‡ä»¶ä¸€å¼ è¯äº‘ï¼‰" and has_chapter_data:
            with st.spinner("æ­£åœ¨ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆè¯äº‘..."):
                for idx, (file_name, cleaned_text) in enumerate(st.session_state["chapter_clean_texts"].items(), 1):
                    if not str(cleaned_text).strip():
                        st.warning(f"ç« èŠ‚ {idx}ï¼š{file_name} æ— æœ‰æ•ˆæ–‡æœ¬ï¼Œè·³è¿‡ï¼")
                        continue

                    if weight_method == "TF-IDF":
                        word2weight = wordcloud_utils.get_tfidf_weights(cleaned_text)
                    else:
                        word2weight = wordcloud_utils.get_textrank_weights(cleaned_text)

                    if not word2weight:
                        st.warning(f"ç« èŠ‚ {idx}ï¼š{file_name} æ— æœ‰æ•ˆè¯æ±‡ç”Ÿæˆè¯äº‘ï¼")
                        continue

                    fig = wordcloud_utils.generate_weighted_wordcloud(word2weight, bg_color, max_words)
                    results["chapter"][file_name] = _fig_to_png_bytes(fig)

        elif generate_mode == "å…¨å±€ç”Ÿæˆï¼ˆæ‰€æœ‰æ–‡ä»¶åˆå¹¶ï¼‰" and has_global_data:
            with st.spinner("æ­£åœ¨ç”Ÿæˆå…¨å±€è¯äº‘..."):
                clean_text = st.session_state["clean_text"]
                if weight_method == "TF-IDF":
                    word2weight = wordcloud_utils.get_tfidf_weights(clean_text)
                else:
                    word2weight = wordcloud_utils.get_textrank_weights(clean_text)

                if not word2weight:
                    st.warning("æ— æœ‰æ•ˆè¯æ±‡ç”Ÿæˆè¯äº‘ï¼")
                    return

                fig = wordcloud_utils.generate_weighted_wordcloud(word2weight, bg_color, max_words)
                results["global"] = _fig_to_png_bytes(fig)

        st.session_state["campus_wordcloud_results"] = results

    results = st.session_state.get("campus_wordcloud_results")
    if isinstance(results, dict) and (results.get("chapter") or results.get("global")):
        st.divider()
        st.subheader("ğŸ“Œ ç”Ÿæˆç»“æœï¼ˆå·²ç¼“å­˜ï¼‰")
        if results.get("generate_mode"):
            st.caption(
                f"æ¨¡å¼ï¼š{results.get('generate_mode')}ï½œæƒé‡æ¨¡å‹ï¼š{results.get('weight_method')}ï½œèƒŒæ™¯ï¼š{results.get('bg_color')}ï½œæœ€å¤§è¯æ•°ï¼š{results.get('max_words')}"
            )

        if results.get("chapter"):
            for idx, (file_name, png) in enumerate(results["chapter"].items(), 1):
                st.subheader(f"ğŸ“– ç« èŠ‚ {idx}ï¼š{file_name}")
                st.image(png, width="stretch")

        if results.get("global"):
            st.subheader("ğŸŒ å…¨å±€æ–‡æœ¬è¯äº‘ï¼ˆæ‰€æœ‰ç« èŠ‚åˆå¹¶ï¼‰")
            st.image(results["global"], width="stretch")
