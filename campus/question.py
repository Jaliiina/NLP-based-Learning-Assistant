import streamlit as st
import random
import re

from aid_integrated.campus import llm_helpers

def extract_topic_from_sentence(sent: str) -> str:
    invalid_starts = {"è¿™äº›", "è¿™ç§", "è¯¥", "å…¶", "å®ƒ", "æ­¤", "ä¸", "å’Œ", "å¯¹äº", "åŸºäº"}

    en_term_pattern = r"[A-Za-z0-9]+(?:-[A-Za-z0-9]+)*"
    en_terms = re.findall(en_term_pattern, sent)
    for term in en_terms:
        professional_en_terms = {"TF", "IDF", "TF-IDF", "TextRank", "NLP", "LDA", "SVM", "CNN", "RNN"}
        if (len(term) >= 2 and (term.upper() in professional_en_terms or 
            (any(c.isupper() for c in term) and not term.islower()))):
            return term.upper() if term.isupper() else term

    chinese_professional_pattern = r"[\u4e00-\u9fa5]{2,6}[ç®—æ³•|æ–¹æ³•|æ­¥éª¤|æŠ€æœ¯|æ¨¡å‹|è§„åˆ™|é€»è¾‘|ç­–ç•¥|æµç¨‹|æ ‡å‡†]"
    chinese_matches = re.findall(chinese_professional_pattern, sent)
    if chinese_matches:
        for match in chinese_matches:
            if not any(match.startswith(ws) for ws in invalid_starts):
                return match

    core_noun_pattern = r"([\u4e00-\u9fa5]{2,6})"
    core_candidates = re.findall(core_noun_pattern, sent)
    invalid_topics = {"æ ¸å¿ƒç›®çš„åœ¨äº", "æŠ¥å‘Šç­‰ç»“æ„æ¸…æ™°", "è¿™äº›é¢„å¤„ç†", "è¯¥æ–¹æ³•é€‚ç”¨äº", "æ ¸å¿ƒåœ¨äº", "ç›¸å…³å†…å®¹", "é‡è¦ä½œç”¨", "åº”ç”¨ä»·å€¼"}
    for candidate in core_candidates:
        if (len(candidate) >= 2 and candidate not in invalid_topics and
            not any(candidate.startswith(ws) for ws in invalid_starts)):
            if not re.search(r"[çš„|åœ°|å¾—|åœ¨|é€šè¿‡|ä½¿ç”¨|å®ç°|ä¸ºäº†]" + candidate, sent):
                return candidate

    return ""

def generate_questions_from_core(core_sentences: list[str], summary: str, question_types: list[str]) -> list[dict]:
    questions = []
    q_id = 1
    global_used_topics = set()  
    used_core_sents = set()     
    MAX_QUESTIONS = 6  

    for core_sent in core_sentences:
        if len(questions) >= MAX_QUESTIONS:
            break
            
        core_sent_stripped = core_sent.strip()
        if not core_sent_stripped or core_sent_stripped in used_core_sents:
            continue
        
        topic = extract_topic_from_sentence(core_sent_stripped)
        if not topic or topic in global_used_topics:
            continue

        global_used_topics.add(topic)
        used_core_sents.add(core_sent_stripped)

        if "æ¦‚å¿µè§£é‡Šé¢˜" in question_types and len(questions) < MAX_QUESTIONS:
            if re.match(r"^[A-Z]+(?:-[A-Z]+)*$", topic):
                question_content = f"{q_id}. è¯·è§£é‡Šã€Œ{topic}ã€çš„å«ä¹‰ï¼Œå¹¶è¯´æ˜å®ƒåœ¨è®²ä¹‰å†…å®¹ä¸­çš„æ ¸å¿ƒä½œç”¨ã€‚\n\n"
            else:
                question_content = f"{q_id}. è¯·ç®€è¦é˜è¿°ã€Œ{topic}ã€çš„å®šä¹‰ï¼Œä»¥åŠå®ƒåœ¨ç›¸å…³çŸ¥è¯†ä½“ç³»ä¸­çš„ä»·å€¼ã€‚\n\n"
            
            questions.append({
                "id": q_id,
                "type": "æ¦‚å¿µè§£é‡Šé¢˜",
                "content": question_content,
                "based_on": core_sent_stripped
            })
            q_id += 1

        if len(questions) >= MAX_QUESTIONS:
            break

        if "å…³é”®å¥ç†è§£é¢˜" in question_types and len(questions) < MAX_QUESTIONS:
            question_content = f"""{q_id}. å¥å­ç†è§£é¢˜ï¼š

è¯·ç»“åˆè®²ä¹‰æ ¸å¿ƒå†…å®¹ï¼Œåˆ†æä¸‹åˆ—å¥å­çš„æ ¸å¿ƒå«ä¹‰åŠå…¶åœ¨çŸ¥è¯†ä½“ç³»ä¸­çš„ä½œç”¨ï¼š

> {core_sent_stripped}

\n\n"""
            questions.append({
                "id": q_id,
                "type": "å…³é”®å¥ç†è§£é¢˜",
                "content": question_content,
                "based_on": core_sent_stripped
            })
            q_id += 1


        if len(questions) >= MAX_QUESTIONS:
            break

        if "ç®€ç­”é¢˜ï¼ˆé‡ç‚¹ä¿¡æ¯æç‚¼ï¼‰" in question_types and len(questions) < MAX_QUESTIONS:
            if re.match(r"^[A-Z]+(?:-[A-Z]+)*$", topic):
                question_content = f"{q_id}. ç®€ç­”é¢˜ï¼š\n\n> è¯·ç»“åˆè®²ä¹‰å†…å®¹ï¼Œæç‚¼ã€Œ{topic}ã€çš„æ ¸å¿ƒåº”ç”¨åœºæ™¯åŠå…³é”®è¦ç‚¹ã€‚\n\n"
            else:
                question_content = f"{q_id}. ç®€ç­”é¢˜ï¼š\n\n> è¯·æç‚¼ä¸ã€Œ{topic}ã€ç›¸å…³çš„æ ¸å¿ƒä¿¡æ¯ï¼ŒåŒ…æ‹¬å…¶å®æ–½æµç¨‹æˆ–åº”ç”¨ä»·å€¼ã€‚\n\n"
            
            questions.append({
                "id": q_id,
                "type": "ç®€ç­”é¢˜ï¼ˆé‡ç‚¹ä¿¡æ¯æç‚¼ï¼‰",
                "content": question_content,
                "based_on": core_sent_stripped
            })
            q_id += 1

        if len(questions) >= MAX_QUESTIONS:
            break

    return questions

def _allocate_question_counts(question_types: list[str]) -> dict[str, int]:
    types = [t for t in question_types if isinstance(t, str) and t.strip()]
    n_types = len(types)
    if n_types <= 0:
        return {}
    per = 6 if n_types == 1 else (3 if n_types == 2 else 2)
    return {t: per for t in types}

def _generate_questions_with_deepseek(
    summary: str,
    core_sentences: list[str],
    question_types: list[str],
    requirements: str,
) -> list[dict]:
    counts = _allocate_question_counts(question_types)
    out: list[dict] = []
    for qtype in question_types:
        n = counts.get(qtype, 0)
        if n <= 0:
            continue
        items = llm_helpers.generate_review_questions(
            summary=summary,
            core_knowledge=core_sentences,
            question_type=qtype,
            n=n,
            requirements=requirements,
        )
        for it in items:
            out.append({"type": qtype, "question": it.get("question", ""), "answer": it.get("answer", "")})
    return out

def render_questions_box(questions: list[dict], title: str):

    if not questions:
        st.info("æš‚æ— æœ‰æ•ˆå¤ä¹ é¢˜ï¼Œè¯·æ£€æŸ¥æ ¸å¿ƒçŸ¥è¯†ç‚¹æ•°æ®æ˜¯å¦å®Œæ•´")
        return

    content = ""
    for q in questions:
        content += f"<div style='margin-bottom: 20px; line-height: 1.6;'>{q['content']}</div>"
        based_on_abbr = q['based_on'][:60] + "..." if len(q['based_on']) > 60 else q['based_on']
        content += f"<div style='font-size: 12px; color: #666; margin-bottom: 15px;'>ï¼ˆå‡ºé¢˜ä¾æ®ï¼š{based_on_abbr}ï¼‰</div>"

    html = f"""
    <div style="margin: 20px 0; padding: 15px; background: #f8f9fa; border-radius: 8px;">
        <h4 style="margin: 0 0 15px 0; color: #2563eb;">ğŸ“˜ {title}ï¼ˆå…±{len(questions)}é¢˜ï¼‰</h4>
        <div>{content}</div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

def render_llm_questions_box(questions: list[dict], title: str, show_answers: bool) -> None:
    if not questions:
        st.info("æš‚æ— æœ‰æ•ˆå¤ä¹ é¢˜ï¼Œè¯·æ£€æŸ¥æ ¸å¿ƒçŸ¥è¯†ç‚¹æ•°æ®æ˜¯å¦å®Œæ•´")
        return

    order = ["æ¦‚å¿µè§£é‡Šé¢˜", "å…³é”®å¥ç†è§£é¢˜", "ç®€ç­”é¢˜ï¼ˆé‡ç‚¹ä¿¡æ¯æç‚¼ï¼‰"]
    by_type: dict[str, list[dict]] = {t: [] for t in order}
    other: list[dict] = []
    for q in questions:
        t = str(q.get("type", "")).strip()
        if t in by_type:
            by_type[t].append(q)
        else:
            other.append(q)

    tabs: list[str] = [t for t in order if by_type[t]]
    if other:
        tabs.append("å…¶ä»–")

    st.markdown(f"#### ğŸ“˜ {title}ï¼ˆå…±{len(questions)}é¢˜ï¼‰")
    if not tabs:
        return

    def _render_items(items: list[dict]) -> None:
        for i, item in enumerate(items, 1):
            q_text = str(item.get("question", "")).strip()
            a_text = str(item.get("answer", "")).strip()
            if q_text:
                st.markdown(f"**{i}. {q_text}**")
            if a_text:
                with st.expander("æŸ¥çœ‹ç­”æ¡ˆ", expanded=show_answers):
                    st.markdown(a_text)
            st.divider()

    if len(tabs) == 1:
        t = tabs[0]
        items = other if t == "å…¶ä»–" else by_type.get(t, [])
        _render_items(items)
        return

    tab_objs = st.tabs(tabs)
    for idx, t in enumerate(tabs):
        with tab_objs[idx]:
            items = other if t == "å…¶ä»–" else by_type.get(t, [])
            _render_items(items)

def render_core_based_question_page():
    st.header("ğŸ“˜ å¤šç±»å‹ä¹ é¢˜ç”Ÿæˆ")

    st.markdown(
        """
        <div style="background-color:#f8fafc;padding:20px;border-radius:16px;border:1px solid #e2e8f0;
box-shadow:0 4px 16px rgba(0,0,0,0.06);margin:16px 0 24px 0;">
  <div style="font-size:16px;color:#1e293b;line-height:1.75;">
    æœ¬é¡µé¢åŸºäº <b style="color:#2563eb">TF-IDF é‡ç‚¹æ®µè½åˆ†æç»“æœ</b>ï¼Œè‡ªåŠ¨ç”Ÿæˆå¤šç§å¤ä¹ é¢˜å‹ï¼š<br/>
    â‘ æ¦‚å¿µè§£é‡Šé¢˜<br/>
    â‘¡å…³é”®å¥ç†è§£é¢˜<br/>
    â‘¢ç®€ç­”é¢˜ï¼ˆé‡ç‚¹ä¿¡æ¯æç‚¼ï¼‰<br/>
  </div>
  <div style="margin-top:12px;background:#eff6ff;padding:12px;border-radius:10px;color:#1e40af;">
    ğŸ§­ <b>ä½¿ç”¨æ–¹å¼ï¼š</b>è¯·å…ˆåœ¨ã€ŒğŸ“ˆ æ–‡æœ¬é‡ç‚¹ä¸ç»“æ„åˆ†æã€é¡µé¢å®Œæˆ TF-IDF è®¡ç®—ã€‚
  </div>
</div>
        """,
        unsafe_allow_html=True
    )

    has_campus_results = isinstance(st.session_state.get("campus_generated_results"), dict)
    if not has_campus_results:
        st.warning("âš ï¸ æœªæ£€æµ‹åˆ°æ ¸å¿ƒçŸ¥è¯†ç‚¹æ•°æ®ï¼Œè¯·å…ˆå‰å¾€ã€ŒğŸ“‹ è®²ä¹‰æ‘˜è¦ä¸æ ¸å¿ƒçŸ¥è¯†ç‚¹æå–ã€é¡µé¢ç”Ÿæˆæ ¸å¿ƒå†…å®¹ï¼")
        return

    campus_results = st.session_state["campus_generated_results"]
    has_chapter_data = bool(campus_results.get("chapter"))
    has_global_data = bool(campus_results.get("global") and (campus_results["global"]["core"] or campus_results["global"]["summary"]))

    if not has_chapter_data and not has_global_data:
        st.warning("âš ï¸ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ•°æ®ä¸ºç©ºï¼Œè¯·å…ˆç”Ÿæˆæœ‰æ•ˆæ ¸å¿ƒå†…å®¹ï¼")
        return

    scope_options: list[str] = []
    if has_global_data:
        scope_options.append("å…¨å±€")
    if has_chapter_data:
        scope_options.append("æŒ‰ç« èŠ‚")
    scope = st.radio("å‡ºé¢˜èŒƒå›´", scope_options, index=0, horizontal=True, key="question_scope")
    use_chapter_data = scope == "æŒ‰ç« èŠ‚"

    st.markdown("<h5 style='margin: 15px 0 8px 0; color: #1e40af;'>é¢˜å‹é€‰æ‹©</h5>", unsafe_allow_html=True)
    selected_question_types = st.multiselect(
        "è¯·é€‰æ‹©è¦ç”Ÿæˆçš„é¢˜å‹",
        options=["æ¦‚å¿µè§£é‡Šé¢˜", "å…³é”®å¥ç†è§£é¢˜", "ç®€ç­”é¢˜ï¼ˆé‡ç‚¹ä¿¡æ¯æç‚¼ï¼‰"],
        default=["æ¦‚å¿µè§£é‡Šé¢˜", "å…³é”®å¥ç†è§£é¢˜", "ç®€ç­”é¢˜ï¼ˆé‡ç‚¹ä¿¡æ¯æç‚¼ï¼‰"],
        key="selected_q_types"
    )

    if not selected_question_types:
        st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ç§é¢˜å‹ï¼")
        return

    requirements = st.text_area(
        "å‡ºé¢˜è¦æ±‚ï¼ˆå¯é€‰ï¼‰",
        value=st.session_state.get("question_requirements", ""),
        placeholder="ä¾‹å¦‚ï¼šè¦†ç›–å®šä¹‰/æµç¨‹/å¯¹æ¯”ï¼›é¢˜å¹²å°½é‡ç»“åˆè¯¾å ‚ä¾‹å­ï¼›ç­”æ¡ˆåˆ†ç‚¹ï¼›éš¾åº¦ä¸­ç­‰ã€‚",
        height=100,
        key="question_requirements",
    )

    show_answers = st.checkbox("é»˜è®¤å±•å¼€æ˜¾ç¤ºç­”æ¡ˆ", value=False, key="show_answers")

    if st.button("ç”Ÿæˆå¤ä¹ é¢˜", type="primary", width="stretch"):
        with st.spinner("æ­£åœ¨åŸºäºæ ¸å¿ƒçŸ¥è¯†ç‚¹ç”Ÿæˆç²¾å‡†å¤ä¹ é¢˜..."):
            generated_questions = {}
            try:
                if use_chapter_data:
                    for file_name, data in campus_results["chapter"].items():
                        core_sentences = data.get("core", [])
                        summary = data.get("summary", "")
                        questions = _generate_questions_with_deepseek(
                            summary=summary,
                            core_sentences=core_sentences,
                            question_types=selected_question_types,
                            requirements=requirements,
                        )
                        generated_questions[file_name] = questions
                else:
                    global_data = campus_results["global"]
                    core_sentences = global_data.get("core", [])
                    summary = global_data.get("summary", "")
                    questions = _generate_questions_with_deepseek(
                        summary=summary,
                        core_sentences=core_sentences,
                        question_types=selected_question_types,
                        requirements=requirements,
                    )
                    generated_questions["global"] = questions

                st.session_state["core_based_generated_questions"] = generated_questions
                total = sum(len(v) for v in generated_questions.values())
                st.success(f"âœ… å¤ä¹ é¢˜ç”Ÿæˆå®Œæˆï¼å…±{total}é“é¢˜ï¼")
            except RuntimeError as e:
                st.error(
                    "âŒ DeepSeek æœªé…ç½®æˆ–ä¸å¯ç”¨ã€‚è¯·åœ¨é¡¹ç›®ç›®å½•çš„ `.streamlit/secrets.toml` é…ç½® `DEEPSEEK_API_KEY`ï¼Œ"
                    "æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ `DEEPSEEK_API_KEY` åé‡è¯•ã€‚"
                )
                st.caption(str(e))
                return
            except Exception as e:
                st.error(f"âŒ DeepSeek å‡ºé¢˜å¤±è´¥ï¼š{str(e)}")
                return

    st.divider()
    st.subheader("ğŸ“ å¤ä¹ é¢˜")

    cached_questions = st.session_state.get("core_based_generated_questions", {})

    if not cached_questions:
        st.markdown(
            """
            <div style="
                margin: 10px 0; 
                border: 1px solid #E5E6EB;
                border-radius: 4px;
                box-shadow: 0 1px 2px rgba(0,0,0,0.05);
            ">
                <div style="
                    background-color: #F5F9FF;
                    padding: 12px 16px;
                    border-bottom: 1px solid #E5E6EB;
                    border-radius: 4px 4px 0 0;
                    font-size: 15px;
                    font-weight: 600;
                    color: #165DFF;
                ">
                    <span style="margin-right: 8px;">â„¹ï¸</span> æç¤º
                </div>
                <div style="
                    background-color: #FFFFFF;
                    padding: 16px;
                    border-radius: 0 0 4px 4px;
                    font-size: 14px;
                    color: #666;
                ">
                    ç‚¹å‡»ã€Œç”Ÿæˆå¤ä¹ é¢˜ã€æŒ‰é’®ï¼Œå³å¯åŸºäºæ ¸å¿ƒçŸ¥è¯†ç‚¹ç”Ÿæˆæœ€å¤š6é“æ— é‡å¤é¢˜ç›®
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )
        return

    if "global" in cached_questions:
        global_questions = cached_questions.get("global", [])
        render_llm_questions_box(global_questions, title="å…¨å±€æ ¸å¿ƒçŸ¥è¯†ç‚¹å¤ä¹ é¢˜", show_answers=show_answers)
    else:
        for idx, (file_name, questions) in enumerate(cached_questions.items(), 1):
            render_llm_questions_box(questions, title=f"ç« èŠ‚ {idx}ï¼š{file_name} æ ¸å¿ƒçŸ¥è¯†ç‚¹å¤ä¹ é¢˜", show_answers=show_answers)
            st.divider()